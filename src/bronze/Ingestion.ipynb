{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb8c81ad-3a4e-4681-9663-5846fe2bb1fa",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Import"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import delta\n",
    "\n",
    "\n",
    "def table_exists(catalog, database, table):\n",
    "  count = (spark.sql(f\"SHOW TABLES FROM {catalog}.{database}\")\n",
    "           .filter(f\"database = '{database}' AND tableName = '{table}' \")\n",
    "           .count())\n",
    "  \n",
    "  return count == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac13c28a-ae0d-4f16-a0f5-bd549ea92150",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Setup"
    }
   },
   "outputs": [],
   "source": [
    "catalog = \"bronze\"\n",
    "schema = \"f1_world\"\n",
    "tableName = dbutils.widgets.get(\"tableName\")\n",
    "TARGET_RACEID = 1141\n",
    "files_split = [\"constructor_results\" ,\"constructor_standings\", \"driver standings\", \"lap_times\", \"pit_stops\", \"qualifying\", \"results\", \"sprint_results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4efca4e4-2414-44e8-9374-1bf31ebbedea",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Ingest√£o Full Load e Split"
    }
   },
   "outputs": [],
   "source": [
    "if not table_exists(catalog, schema, tableName):\n",
    "  print(f\"Criando tabela {tableName}\")\n",
    "\n",
    "  if tableName in files_split:\n",
    "    df_split = spark.read.format(\"csv\").options(header=\"true\").load(f\"/Volumes/raw/{schema}/{tableName}/\")\n",
    "    \n",
    "\n",
    "    df_batch = df_split.filter(df_split.raceId != TARGET_RACEID)\n",
    "    df_batch.coalesce(1).write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{catalog}.{schema}.{tableName}\")\n",
    "    print(\"Tabela delta criado com sucesso\")\n",
    "    \n",
    "\n",
    "    df_streaming = df_split.filter(df_split.raceId == TARGET_RACEID)\n",
    "    df_streaming_pandas = df_streaming.toPandas()\n",
    "    df_streaming_pandas.to_parquet(f\"/Volumes/raw/{schema}/streaming_source/{tableName}.parquet\", index=False)\n",
    "    print(\"Arquivo streaming criado com sucesso\")\n",
    "\n",
    "  else:\n",
    "    df_full = spark.read.format(\"csv\").options(header=\"true\").load(f\"/Volumes/raw/{schema}/{tableName}/\")\n",
    "\n",
    "    df_full.coalesce(1).write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{catalog}.{schema}.{tableName}\")\n",
    "else:\n",
    "  print(f\"Tabela {tableName} ja existe\")\n",
    "                                        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6547989020779659,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Ingestion",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
